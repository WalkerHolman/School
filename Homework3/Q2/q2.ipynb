{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "057d6c12-9a60-4203-b5f0-34db2d33d96c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# STARTER CODE - DO NOT EDIT THIS CELL\n",
    "\n",
    "from pyspark.sql.functions import*\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9daa96c-24de-4770-99af-ce9fab1f6d1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# STARTER CODE - DO NOT EDIT THIS CELL\n",
    "\n",
    "#from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "customSchema = StructType([\n",
    "    StructField(\"lpep_pickup_datetime\", StringType(), True),\n",
    "    StructField(\"lpep_dropoff_datetime\", StringType(), True),\n",
    "    StructField(\"PULocationID\", IntegerType(), True),\n",
    "    StructField(\"DOLocationID\", IntegerType(), True),\n",
    "    StructField(\"passenger_count\", IntegerType(), True),\n",
    "    StructField(\"trip_distance\", FloatType(), True),\n",
    "    StructField(\"fare_amount\", FloatType(), True),\n",
    "    StructField(\"payment_type\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a44b857-d13a-4088-8cd8-25b112ab1b11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>lpep_pickup_datetime</th><th>lpep_dropoff_datetime</th><th>PULocationID</th><th>DOLocationID</th><th>passenger_count</th><th>trip_distance</th><th>fare_amount</th><th>payment_type</th></tr></thead><tbody><tr><td>12/21/2018 15:17</td><td>12/21/2018 15:18</td><td>264</td><td>264</td><td>5</td><td>0.0</td><td>3.0</td><td>2</td></tr><tr><td>01/01/2019 0:10</td><td>01/01/2019 0:16</td><td>97</td><td>49</td><td>2</td><td>0.86</td><td>6.0</td><td>2</td></tr><tr><td>01/01/2019 0:27</td><td>01/01/2019 0:31</td><td>49</td><td>189</td><td>2</td><td>0.66</td><td>4.5</td><td>1</td></tr><tr><td>01/01/2019 0:46</td><td>01/01/2019 1:04</td><td>189</td><td>17</td><td>2</td><td>2.68</td><td>13.5</td><td>1</td></tr><tr><td>01/01/2019 0:19</td><td>01/01/2019 0:39</td><td>82</td><td>258</td><td>1</td><td>4.53</td><td>18.0</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "12/21/2018 15:17",
         "12/21/2018 15:18",
         264,
         264,
         5,
         0,
         3,
         2
        ],
        [
         "01/01/2019 0:10",
         "01/01/2019 0:16",
         97,
         49,
         2,
         0.86,
         6,
         2
        ],
        [
         "01/01/2019 0:27",
         "01/01/2019 0:31",
         49,
         189,
         2,
         0.66,
         4.5,
         1
        ],
        [
         "01/01/2019 0:46",
         "01/01/2019 1:04",
         189,
         17,
         2,
         2.68,
         13.5,
         1
        ],
        [
         "01/01/2019 0:19",
         "01/01/2019 0:39",
         82,
         258,
         1,
         4.53,
         18,
         2
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "lpep_pickup_datetime",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "lpep_dropoff_datetime",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "PULocationID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "DOLocationID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "passenger_count",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "trip_distance",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "fare_amount",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "payment_type",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STARTER CODE - YOU CAN LOAD ANY FILE WITH A SIMILAR SYNTAX.\n",
    "# Correct file path for Databricks File System (update if you are using a different volume or file name)\n",
    "file_path = \"/Volumes/workspace/default/q2vol/nyc-tripdata.csv\"\n",
    "\n",
    "# Read the CSV file using Spark DataFrame\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(file_path)\n",
    "\n",
    "display(df.limit(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3f85828-e32b-426d-b2c8-ed815c3e3e28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>LocationID</th><th>Borough</th><th>Zone</th><th>service_zone</th></tr></thead><tbody><tr><td>1</td><td>EWR</td><td>Newark Airport</td><td>EWR</td></tr><tr><td>2</td><td>Queens</td><td>Jamaica Bay</td><td>Boro Zone</td></tr><tr><td>3</td><td>Bronx</td><td>Allerton/Pelham Gardens</td><td>Boro Zone</td></tr><tr><td>4</td><td>Manhattan</td><td>Alphabet City</td><td>Yellow Zone</td></tr><tr><td>5</td><td>Staten Island</td><td>Arden Heights</td><td>Boro Zone</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "EWR",
         "Newark Airport",
         "EWR"
        ],
        [
         2,
         "Queens",
         "Jamaica Bay",
         "Boro Zone"
        ],
        [
         3,
         "Bronx",
         "Allerton/Pelham Gardens",
         "Boro Zone"
        ],
        [
         4,
         "Manhattan",
         "Alphabet City",
         "Yellow Zone"
        ],
        [
         5,
         "Staten Island",
         "Arden Heights",
         "Boro Zone"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "LocationID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Borough",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Zone",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "service_zone",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOAD THE \"taxi_zone_lookup.csv\" FILE SIMILARLY AS ABOVE. CAST ANY COLUMN TO APPROPRIATE DATA TYPE IF NECESSARY.\n",
    "\n",
    "#ENTER THE CODE BELOW\n",
    "# Correct file path for the taxi zone lookup dataset\n",
    "zone_file_path = \"/Volumes/workspace/default/q2vol/taxi_zone_lookup.csv\"\n",
    "\n",
    "# Read the CSV file using Spark DataFrame\n",
    "taxi_zone_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(zone_file_path)\n",
    "\n",
    "# (Optional) Cast specific columns if necessary, e.g., LocationID to Integer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "taxi_zone_df = taxi_zone_df.withColumn(\"LocationID\", col(\"LocationID\").cast(\"int\"))\n",
    "\n",
    "display(taxi_zone_df.limit(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c211a70-cb15-4c86-a92f-61b3c912063e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+------------+------------+---------------+-------------+-----------+------------+\n",
      "|lpep_pickup_datetime|lpep_dropoff_datetime|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|payment_type|\n",
      "+--------------------+---------------------+------------+------------+---------------+-------------+-----------+------------+\n",
      "|    12/21/2018 15:17|     12/21/2018 15:18|         264|         264|              5|          0.0|        3.0|           2|\n",
      "|     01/01/2019 0:10|      01/01/2019 0:16|          97|          49|              2|         0.86|        6.0|           2|\n",
      "|     01/01/2019 0:27|      01/01/2019 0:31|          49|         189|              2|         0.66|        4.5|           1|\n",
      "|     01/01/2019 0:46|      01/01/2019 1:04|         189|          17|              2|         2.68|       13.5|           1|\n",
      "|     01/01/2019 0:19|      01/01/2019 0:39|          82|         258|              1|         4.53|       18.0|           2|\n",
      "+--------------------+---------------------+------------+------------+---------------+-------------+-----------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "#// STARTER CODE \n",
    "# // Some commands that you can use to see your dataframes and results of the operations. You can comment the df.show(5) and uncomment display(df) to see the data differently. You will find these two functions useful in reporting your results.\n",
    "df.show(5)\n",
    "#display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "001aed80-25b1-4828-9668-3aae948f4a46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+------------+------------+---------------+-------------+-----------+------------+\n",
      "|lpep_pickup_datetime|lpep_dropoff_datetime|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|payment_type|\n",
      "+--------------------+---------------------+------------+------------+---------------+-------------+-----------+------------+\n",
      "|     01/01/2019 0:46|      01/01/2019 1:04|         189|          17|              2|         2.68|       13.5|           1|\n",
      "|     01/01/2019 0:19|      01/01/2019 0:39|          82|         258|              1|         4.53|       18.0|           2|\n",
      "|     01/01/2019 0:47|      01/01/2019 1:00|         255|          33|              1|         3.77|       13.5|           1|\n",
      "|     01/01/2019 0:12|      01/01/2019 0:30|          76|         225|              1|          4.1|       16.0|           1|\n",
      "|     01/01/2019 0:16|      01/01/2019 0:39|          25|          89|              1|         7.75|       25.5|           1|\n",
      "+--------------------+---------------------+------------+------------+---------------+-------------+-----------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# // STARTER CODE - DO NOT EDIT THIS CELL\n",
    "# Filter the data to only keep the rows where \"PULocationID\" and the \"DOLocationID\" are different and the \"trip_distance\" is strictly greater than 2.0 (>2.0).\n",
    "\n",
    "# VERY VERY IMPORTANT: ALL THE SUBSEQUENT OPERATIONS MUST BE PERFORMED ON THIS FILTERED DATA\n",
    "\n",
    "df_filter = df.filter((df.PULocationID != df.DOLocationID) & (df.trip_distance > 2.0))\n",
    "df_filter.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f4f23c7-a3de-40f8-81ce-0aa4b7d8621d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>DOLocationID</th><th>number_of_dropoffs</th></tr></thead><tbody><tr><td>61</td><td>5937</td></tr><tr><td>138</td><td>5146</td></tr><tr><td>239</td><td>4133</td></tr><tr><td>244</td><td>4006</td></tr><tr><td>42</td><td>3859</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         61,
         5937
        ],
        [
         138,
         5146
        ],
        [
         239,
         4133
        ],
        [
         244,
         4006
        ],
        [
         42,
         3859
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "DOLocationID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "number_of_dropoffs",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PART 1a: The top-5 most popular drop locations - \"DOLocationID\", sorted in descending order - if there is a tie, then one with lower \"DOLocationID\" gets listed first\n",
    "\n",
    "# Output Schema: DOLocationID int, number_of_dropoffs int \n",
    "\n",
    "# Hint: Checkout the groupBy(), orderBy() and count() functions.\n",
    "\n",
    "# ENTER THE CODE BELOW\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "# Group by DOLocationID and count number of dropoffs\n",
    "top_dropoffs = (\n",
    "    df_filter.groupBy(\"DOLocationID\")\n",
    "    .agg(count(\"*\").alias(\"number_of_dropoffs\"))\n",
    "    .orderBy(col(\"number_of_dropoffs\").desc(), col(\"DOLocationID\").asc())\n",
    "    .limit(5)\n",
    ")\n",
    "\n",
    "display(top_dropoffs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97b67aa8-dcb1-472e-b819-4200867fa9ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PULocationID</th><th>number_of_pickups</th></tr></thead><tbody><tr><td>74</td><td>17360</td></tr><tr><td>75</td><td>13299</td></tr><tr><td>244</td><td>9958</td></tr><tr><td>41</td><td>9645</td></tr><tr><td>82</td><td>9306</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         74,
         17360
        ],
        [
         75,
         13299
        ],
        [
         244,
         9958
        ],
        [
         41,
         9645
        ],
        [
         82,
         9306
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "PULocationID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "number_of_pickups",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PART 1b: The top-5 most popular pickup locations - \"PULocationID\", sorted in descending order - if there is a tie, then one with lower \"PULocationID\" gets listed first \n",
    "\n",
    "# Output Schema: PULocationID int, number_of_pickups int\n",
    "\n",
    "# ENTER THE CODE BELOW\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "# Group by PULocationID and count number of pickups\n",
    "top_pickups = (\n",
    "    df_filter.groupBy(\"PULocationID\")\n",
    "    .agg(count(\"*\").alias(\"number_of_pickups\"))\n",
    "    .orderBy(col(\"number_of_pickups\").desc(), col(\"PULocationID\").asc())\n",
    "    .limit(5)\n",
    ")\n",
    "\n",
    "display(top_pickups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c861bca-506f-4308-bf95-33101a455c00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>LocationID</th><th>number_activities</th></tr></thead><tbody><tr><td>74</td><td>20292</td></tr><tr><td>75</td><td>16326</td></tr><tr><td>244</td><td>13964</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         74,
         20292
        ],
        [
         75,
         16326
        ],
        [
         244,
         13964
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "LocationID",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "number_activities",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PART 2: List the top-3 locations with the maximum overall activity, i.e. sum of all pickups and all dropoffs at that LocationID. In case of a tie, the lower LocationID gets listed first.\n",
    "\n",
    "# Output Schema: LocationID int, number_activities int\n",
    "\n",
    "# Hint: In order to get the result, you may need to perform a join operation between the two dataframes that you created in earlier parts (to come up with the sum of the number of pickups and dropoffs on each location). \n",
    "\n",
    "# ENTER THE CODE BELOW\n",
    "from pyspark.sql.functions import col, count, coalesce\n",
    "\n",
    "# Count pickups by PULocationID\n",
    "pickup_counts = (\n",
    "    df_filter.groupBy(\"PULocationID\")\n",
    "    .agg(count(\"*\").alias(\"number_of_pickups\"))\n",
    ")\n",
    "\n",
    "# Count dropoffs by DOLocationID\n",
    "dropoff_counts = (\n",
    "    df_filter.groupBy(\"DOLocationID\")\n",
    "    .agg(count(\"*\").alias(\"number_of_dropoffs\"))\n",
    ")\n",
    "\n",
    "# Join on matching LocationIDs (outer join ensures all locations are included)\n",
    "activity_df = (\n",
    "    pickup_counts.join(\n",
    "        dropoff_counts,\n",
    "        pickup_counts.PULocationID == dropoff_counts.DOLocationID,\n",
    "        \"outer\"\n",
    "    )\n",
    "    .select(\n",
    "        coalesce(col(\"PULocationID\"), col(\"DOLocationID\")).alias(\"LocationID\"),\n",
    "        (coalesce(col(\"number_of_pickups\"), col(\"number_of_dropoffs\")) +\n",
    "         coalesce(col(\"number_of_dropoffs\"), col(\"number_of_pickups\"))).alias(\"number_activities\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Sort descending by activity count, tie-break by lower LocationID, and limit to top 3\n",
    "top_activity = activity_df.orderBy(col(\"number_activities\").desc(), col(\"LocationID\").asc()).limit(3)\n",
    "\n",
    "display(top_activity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "343fde80-abb3-4eab-9548-a88ae6b55fd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PART 3: List all the boroughs (including \"Unknown\" and \"EWR\") in the order of having the highest to lowest number of activities (i.e. sum of all pickups and all dropoffs at that LocationID), along with the total number of activity counts for each borough in NYC during that entire period of time.\n",
    "\n",
    "# Output Schema: Borough string, total_number_activities int\n",
    "\n",
    "# Hint: You can use the dataframe obtained from the previous part, and will need to do the join with the 'taxi_zone_lookup' dataframe. Also, checkout the \"agg\" function applied to a grouped dataframe.\n",
    "\n",
    "# ENTER THE CODE BELOW\n",
    "from pyspark.sql.functions import col, sum as Fsum\n",
    "\n",
    "# Build per-LocationID counts for pickups and dropoffs, then union and aggregate\n",
    "pickup_counts = (\n",
    "    df_filter.groupBy(\"PULocationID\").count()\n",
    "    .select(col(\"PULocationID\").alias(\"LocationID\"), col(\"count\").alias(\"cnt\"))\n",
    ")\n",
    "\n",
    "dropoff_counts = (\n",
    "    df_filter.groupBy(\"DOLocationID\").count()\n",
    "    .select(col(\"DOLocationID\").alias(\"LocationID\"), col(\"count\").alias(\"cnt\"))\n",
    ")\n",
    "\n",
    "activity_df = (\n",
    "    pickup_counts.unionByName(dropoff_counts)\n",
    "    .groupBy(\"LocationID\")\n",
    "    .agg(Fsum(\"cnt\").alias(\"number_activities\"))\n",
    ")\n",
    "\n",
    "# Join with taxi zone lookup to get Borough, aggregate activities per Borough\n",
    "borough_activity = (\n",
    "    taxi_zone_df.select(\"LocationID\", \"Borough\")\n",
    "    .join(activity_df, \"LocationID\", \"left\")\n",
    "    .groupBy(\"Borough\")\n",
    "    .agg(Fsum(\"number_activities\").alias(\"total_number_activities\"))\n",
    "    .orderBy(col(\"total_number_activities\").desc(), col(\"Borough\").asc())\n",
    ")\n",
    "\n",
    "display(borough_activity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3645a90b-2d13-4f27-9cfd-20eb2391f865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PART 4: List the top 2 days of week with the largest number of daily average pickups, along with the average number of pickups on each of the 2 days in descending order (no rounding off required). Here, the average pickup is calculated by taking an average of the number of pick-ups on different dates falling on the same day of the week. For example, 02/01/2021, 02/08/2021 and 02/15/2021 are all Mondays, so the average pick-ups for these is the sum of the pickups on each date divided by 3.\n",
    "\n",
    "# Note: The day of week is a string of the day’s full spelling, e.g., \"Monday\" instead of the\t\tnumber 1 or \"Mon\". Also, the pickup_datetime is in the format: yyyy-mm-dd.\n",
    "\n",
    "# Output Schema: day_of_week string, avg_count float\n",
    "\n",
    "# Hint: You may need to group by the \"date\" (without time stamp - time in the day) first. Checkout \"date_format\" and \"to_date\" functions.\n",
    "\n",
    "# ENTER THE CODE BELOW\n",
    "# Use df_filter as mandated in the instructions\n",
    "# Parse pickup timestamp, derive date, count daily pickups, then average by weekday\n",
    "pickup_with_date = (\n",
    "    df_filter\n",
    "    .withColumn(\"pickup_ts\", to_timestamp(col(\"lpep_pickup_datetime\"), \"MM/dd/yyyy H:mm\"))\n",
    "    .withColumn(\"pickup_date\", to_date(col(\"pickup_ts\")))\n",
    ")\n",
    "\n",
    "daily_counts = (\n",
    "    pickup_with_date\n",
    "    .groupBy(\"pickup_date\")\n",
    "    .agg(count(\"*\").alias(\"daily_pickups\"))\n",
    ")\n",
    "\n",
    "result_part4 = (\n",
    "    daily_counts\n",
    "    .withColumn(\"day_of_week\", date_format(col(\"pickup_date\"), \"EEEE\"))\n",
    "    .groupBy(\"day_of_week\")\n",
    "    .agg(avg(col(\"daily_pickups\")).alias(\"avg_count\"))\n",
    "    .orderBy(col(\"avg_count\").desc())\n",
    "    .limit(2)\n",
    ")\n",
    "\n",
    "display(result_part4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c67b00d-00c5-465e-9932-16182516b1b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PART 5: For each particular hour of a day (0 to 23, 0 being midnight) - in their order from 0 to 23, find the zone in Brooklyn borough with the LARGEST number of pickups. \n",
    "\n",
    "# Note: All dates for each hour should be included.\n",
    "\n",
    "# Output Schema: hour_of_day int, zone string, max_count int\n",
    "\n",
    "# Hint: You may need to use \"Window\" over hour of day, along with \"group by\" to find the MAXIMUM count of pickups\n",
    "\n",
    "# ENTER THE CODE BELOW\n",
    "# Join pickups with taxi zone lookup, filter to Brooklyn, compute hour, and pick max per hour\n",
    "pickups_brooklyn = (\n",
    "    df_filter\n",
    "    .join(taxi_zone_df.select(\"LocationID\", \"Borough\", \"Zone\"), df_filter.PULocationID == taxi_zone_df.LocationID, \"inner\")\n",
    "    .filter(col(\"Borough\") == \"Brooklyn\")\n",
    "    .withColumn(\"pickup_ts\", to_timestamp(col(\"lpep_pickup_datetime\"), \"MM/dd/yyyy H:mm\"))\n",
    "    .withColumn(\"hour_of_day\", hour(col(\"pickup_ts\")))\n",
    ")\n",
    "\n",
    "counts = (\n",
    "    pickups_brooklyn\n",
    "    .groupBy(\"hour_of_day\", \"Zone\")\n",
    "    .agg(count(\"*\").alias(\"cnt\"))\n",
    ")\n",
    "\n",
    "w = Window.partitionBy(\"hour_of_day\").orderBy(col(\"cnt\").desc(), col(\"Zone\").asc())\n",
    "\n",
    "result_part5 = (\n",
    "    counts\n",
    "    .withColumn(\"rn\", row_number().over(w))\n",
    "    .filter(col(\"rn\") == 1)\n",
    "    .select(col(\"hour_of_day\").cast(\"int\").alias(\"hour_of_day\"), col(\"Zone\").alias(\"zone\"), col(\"cnt\").alias(\"max_count\"))\n",
    "    .orderBy(col(\"hour_of_day\").asc())\n",
    ")\n",
    "\n",
    "display(result_part5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50ca7584-0519-4522-8655-08765c43d92e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PART 6 - Find which 3 different days in the month of January, in Manhattan, saw the largest positive percentage increase in pick-ups compared to the previous day, in the order from largest percentage increase to smallest percentage increase \n",
    "\n",
    "# Note: All years need to be aggregated to calculate the pickups for a specific day of January. The change from Dec 31 to Jan 1 can be excluded.\n",
    "\n",
    "# Output Schema: day int, percent_change float\n",
    "\n",
    "# Hint: You might need to use lag function, over a window ordered by day of month.\n",
    "\n",
    "# ENTER THE CODE BELOW\n",
    "# Restrict to Manhattan pickups, parse pickup timestamp, keep January only\n",
    "manhattan_pickups = (\n",
    "    df_filter\n",
    "    .join(taxi_zone_df.select(\"LocationID\", \"Borough\"), df_filter.PULocationID == taxi_zone_df.LocationID, \"inner\")\n",
    "    .filter(col(\"Borough\") == \"Manhattan\")\n",
    "    .withColumn(\"pickup_ts\", to_timestamp(col(\"lpep_pickup_datetime\"), \"MM/dd/yyyy H:mm\"))\n",
    "    .filter(month(col(\"pickup_ts\")) == 1)\n",
    "    .withColumn(\"day\", dayofmonth(col(\"pickup_ts\")))\n",
    ")\n",
    "\n",
    "# Total pickups per day of January across all years\n",
    "daily = (\n",
    "    manhattan_pickups\n",
    "    .groupBy(\"day\")\n",
    "    .agg(count(\"*\").alias(\"pickups\"))\n",
    ")\n",
    "\n",
    "# Compute percent change vs previous day number (exclude Jan 1 automatically via NULL prev)\n",
    "w = Window.orderBy(col(\"day\").asc())\n",
    "\n",
    "result_part6 = (\n",
    "    daily\n",
    "    .withColumn(\"prev_pickups\", lag(\"pickups\").over(w))\n",
    "    .withColumn(\n",
    "        \"percent_change\",\n",
    "        when(col(\"prev_pickups\") > 0, (col(\"pickups\") - col(\"prev_pickups\")) * 100.0 / col(\"prev_pickups\"))\n",
    "    )\n",
    "    .filter(col(\"percent_change\").isNotNull() & (col(\"percent_change\") > 0))\n",
    "    .orderBy(col(\"percent_change\").desc(), col(\"day\").asc())\n",
    "    .select(col(\"day\").cast(\"int\").alias(\"day\"), col(\"percent_change\"))\n",
    "    .limit(3)\n",
    ")\n",
    "\n",
    "display(result_part6)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "q2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
