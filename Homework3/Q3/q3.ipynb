{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Q3 [35 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Notices\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: <strong>REMOVE</strong> any print statements added to cells with \"#export\" that are used for debugging purposes befrore submitting because they will crash the autograder in Gradescope. Any additional cells can be used for testing purposes at the bottom. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> remove any comment that says \"#export\" because that will crash the autograder in Gradescope. We use this comment to export your code in these cells for grading.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> import any additional libraries into this workbook.\n",
    "</div>\n",
    "\n",
    "All instructions, code comments, etc. in this notebook **are part of the assignment instructions**. That is, if there is instructions about completing a task in this notebook, that task is not optional.  \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    You <strong>must</strong> implement the following functions in this notebook to receive credit.\n",
    "</div>\n",
    "\n",
    "`user()` - 1 point\n",
    "\n",
    "`trip_statistics()` - 3 points\n",
    "\n",
    "`busiest_hour()` - 5 points\n",
    "\n",
    "`most_freq_pickup_locations()` - 5 points\n",
    "\n",
    "`avg_trip_distance_and_duration()` - 6 points\n",
    "\n",
    "`most_freq_peak_hour_fares()` - 10 points\n",
    "\n",
    "Each function will be auto-graded using different sets of parameters or data, to ensure that values are not hard-coded.  You may assume we will only use your code to work with data from the NYC-TLC dataset during auto-grading.\n",
    "\n",
    "In addition, you will also submit the resulting output csv from most_freq_peak_hour_fares() as output_large.csv.\n",
    "\n",
    "`output_large.csv` - 5 points\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> remove or modify the following utility functions:\n",
    "</div>\n",
    "\n",
    "`load_data()`\n",
    "\n",
    "`main()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> remodify the below cell. It contains the function for loading data and all imports, and the function for running your code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "#### DO NOT CHANGE ANYTHING IN THIS CELL ####\n",
    "\n",
    "def load_data(size='small'):\n",
    "    # Loads the data for this question. Do not change this function.\n",
    "    # This function should only be called with the parameter 'small' or 'large'\n",
    "    \n",
    "    if size != 'small' and size != 'large':\n",
    "        print(\"Invalid size parameter provided. Use only 'small' or 'large'.\")\n",
    "        return\n",
    "    \n",
    "    input_bucket = \"s3://cse6242-hw3-q3\"\n",
    "    \n",
    "    # Load Trip Data\n",
    "    trips_path = '/'+size+'/yellow_tripdata*'\n",
    "    trips = spark.read.csv(input_bucket + trips_path, header=True, inferSchema=True)\n",
    "    \n",
    "    # Load Zone Data\n",
    "    zones_path = '/'+size+'/taxi*'\n",
    "    zones = spark.read.csv(input_bucket + zones_path, header=True, inferSchema=True)\n",
    "    \n",
    "    return trips, zones\n",
    "    \n",
    "def main(size, bucket):\n",
    "    # Runs your functions\n",
    "    trips, zones = load_data(size=size)\n",
    "    \n",
    "    print(\"User:\", user())\n",
    "    print()\n",
    "    \n",
    "    print(\"Trip Statistics:\")\n",
    "    ts = trip_statistics(trips)\n",
    "    ts.show()\n",
    "    print()\n",
    "    \n",
    "    print(\"Busiest Hour:\")\n",
    "    bh = busiest_hour(trips)\n",
    "    bh.show(24)\n",
    "    print()\n",
    "    \n",
    "    print(\"Most Frequent Pickup Locations:\")\n",
    "    mfpl = most_freq_pickup_locations(trips)\n",
    "    mfpl.show()\n",
    "    print()\n",
    "    \n",
    "    print(\"Average Trip Distance and Duration:\")\n",
    "    atdd = avg_trip_distance_and_duration(trips)\n",
    "    atdd.show(n=24)\n",
    "    print()\n",
    "    \n",
    "    print(\"Most Frequent Peak Hour Fares:\")\n",
    "    mfphf = most_freq_peak_hour_fares(trips, zones)\n",
    "    mfphf.show()\n",
    "    mfphf.coalesce(1).write.option(\"header\",\"true\").mode(\"overwrite\").csv('{}/output_{}'.format(bucket, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the below functions for this assignment:\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> change any function inputs or outputs, and ensure that the dataframes your code returns align with the schema definitions commented in each function. Do <strong>NOT</strong> remove the #export comment from each of the code blocks either. This can prevent your code from being converted to a python file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 [1 pt] Update the `user()` function\n",
    "This function should return your GT username, eg: gburdell3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def user():\n",
    "    return 'gburdell3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 [3 pts] Update the `trip_statistics()` function\n",
    "This function performs exploratory data analysis on the column trip_distance. Compute basic statistics (count, mean, stdev, min, max) for trip_distance. \n",
    "\n",
    "Example output formatting:\n",
    "\n",
    "```\n",
    "+-------+------------------+\n",
    "|summary|     trip_distance|\n",
    "+-------+------------------+\n",
    "|  count|           xxxxxxx|\n",
    "|   mean|           xxxxxxx|\n",
    "| stddev|           xxxxxxx|\n",
    "|    min|           xxxxxxx|\n",
    "|    max|           xxxxxxx|\n",
    "+-------+------------------+\n",
    "```\n",
    "Tip: Is there a PySpark Dataframe function you can use to solve this in a single line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def trip_statistics(trips):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 [5 pts] Update the `busiest_hour()` function\n",
    "\n",
    "Determine the hour of the day with the highest number of trips. Display the hour (0-23) and the corresponding trip count.\n",
    "\n",
    "Returns a PySpark DataFrame with a single row showing the hour with the highest trip count and the corresponding number of trips. Use column names: `hour`, `trip_count`.\n",
    "\n",
    "Example output formatting:\n",
    "\n",
    "```\n",
    "+----+----------+\n",
    "|hour|trip_count|\n",
    "+----+----------+\n",
    "|  xx|    xxxxxx|\n",
    "+----+----------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def busiest_hour(trips):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 [5 pts] Update the `most_freq_pickup_locations()` function\n",
    "Top 10 Most Frequent Pickup Locations\n",
    "\n",
    "Identify the top 10 pickup locations (by `PULocationID`) with the highest number of trips. Display the location IDs along with their corresponding trip counts.\n",
    "\n",
    "Return a PySpark DataFrame with the top 10 rows ordered by `trip_count` in descending order. Use column names: `PULocationID`, `trip_count`.\n",
    "\n",
    "Expected Output:\n",
    "\n",
    "A table with 10 rows listing the `PULocationID` values and the number of trips observed for each, ordered from most to least frequent.\n",
    "\n",
    "Example output formatting:\n",
    "```\n",
    "+------------+----------+\n",
    "|PULocationID|trip_count|\n",
    "+------------+----------+\n",
    "|         xxx|    xxxxxx|\n",
    "|         xxx|    xxxxxx|\n",
    "|         xxx|    xxxxxx|\n",
    "|         xxx|    xxxxxx|\n",
    "|         ...|    ......|\n",
    "+------------+----------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def most_freq_pickup_locations(trips): \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 [6 pts] Update the `avg_trip_distance_and_duration()` function\n",
    "Average Trip Distance and Duration by Hour\n",
    "\n",
    "Calculate the average trip distance and average trip duration by pickup hour (0-23), using `tpep_pickup_datetime` for the hour. Display the hour along with the corresponding averages.\n",
    "\n",
    "Compute trip duration in minutes (difference between drop-off time and pickup time).\n",
    "\n",
    "Exclude rows where `tpep_pickup_datetime` or `tpep_dropoff_datetime` is null and where `trip_distance` <= 0. No additional outlier filtering or rounding is required.\n",
    "\n",
    "Note: You can use `unix_timestamp` to help with calculating the duration.\n",
    "\n",
    "Expected Output:\n",
    "\n",
    "A table with 24 rows (hours 0-23) showing each hour ordered ascending along with the average trip distance and average trip duration for that hour. Use column names: `hour`, `avg_trip_distance`, `avg_trip_duration`.\n",
    "\n",
    "Example output formatting:\n",
    "```\n",
    "+----+------------------+------------------+\n",
    "|hour| avg_trip_distance| avg_trip_duration|\n",
    "+----+------------------+------------------+\n",
    "|   0|           xxxxxxx|           xxxxxxx|\n",
    "|   1|           xxxxxxx|           xxxxxxx|\n",
    "|   2|           xxxxxxx|           xxxxxxx|\n",
    "|   3|           xxxxxxx|           xxxxxxx|\n",
    "| ...|               ...|               ...|\n",
    "|  23|           xxxxxxx|           xxxxxxx|\n",
    "+----+------------------+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def avg_trip_distance_and_duration(trips):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 [10 pts] Update the `most_freq_peak_hour_fares()` function\n",
    "Top 10 Most Frequent Routes During Peak Hours\n",
    "\n",
    "Identify the top 10 most frequent routes (combinations of `PULocationID` and `DOLocationID`) during peak hours and return route-level statistics. For this question:\n",
    "\n",
    "- Peak-hour windows are 7:00 - 8:59 (morning) and 16:00 - 18:59 (evening). Consider trips whose pickup hour falls within these windows.\n",
    "- Exclude rows where `PULocationID` or `DOLocationID` is null.\n",
    "- Exclude routes where `PULocationID` equals `DOLocationID` (a valid route must have different pickup and drop-off locations).\n",
    "\n",
    "For each route, compute:\n",
    "\n",
    "- `trip_count`: number of trips for that route during peak hours, and\n",
    "- `avg_total_fare`: the average of the trip total_amount for that route, rounded to two decimal places.\n",
    "\n",
    "Join the route results with the provided zones dataset to include human-readable zone names for pickup and dropoff. Return a PySpark DataFrame with the following columns (in this order):\n",
    "\n",
    "`PULocationID`, `PUZone`, `DOLocationID`, `DOZone`, `trip_count`, `avg_total_fare`.\n",
    "\n",
    "Expected Output:\n",
    "\n",
    "A table with 10 rows showing the top 10 routes during peak hours ordered by `trip_count` descending. If multiple routes share the same `trip_count`, any stable ordering among them is acceptable as long as results are ordered by `trip_count` descending.\n",
    "\n",
    "Example output formatting:\n",
    "```\n",
    "+------------+------+------------+------+----------+--------------+\n",
    "|PULocationID|PUZone|DOLocationID|DOZone|trip_count|avg_total_fare|\n",
    "+------------+------+------------+------+----------+--------------+\n",
    "|xxx         |xxx   |xxx         |xxx   |xxx       |xx.xx         |\n",
    "|xxx         |xxx   |xxx         |xxx   |xxx       |xx.xx         |\n",
    "|xxx         |xxx   |xxx         |xxx   |xxx       |xx.xx         |\n",
    "|...         |...   |...         |...   |...       |...           |\n",
    "+------------+------+------------+------+----------+--------------|\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def most_freq_peak_hour_fares(trips, zones):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 [5 pts] q3_output_large.csv\n",
    "The CSV output from running `most_freq_peak_hour_fares(trips, zones)` on the large dataset.\n",
    "\n",
    "- Run the `main` function with `size='large'` to generate the file in the S3 bucket you created in the AWS setup.\n",
    "- Download the generated file from S3 and rename it to `q3_output_large.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>Submission</h2>\n",
    "\n",
    "<p>Once you have finished coding, you can export the notebook from <code>Notebook Explorer</code> by selecting your notebook and clicking <code>Export File</code> from the Actions dropdown.</p>\n",
    "\n",
    "<p>Submit this notebook (q3.ipynb) along with your CSV file (q3_output_large.csv) to Gradescope.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "  <h2>Testing</h2>\n",
    "\n",
    "  <p>You may use the cell below for any additional testing; however, any code written here will not be run or used during grading.</p>\n",
    "\n",
    "  <ul>\n",
    "    <li>You can run the <code>main</code> function on different dataset sizes to test your work, or run the functions individually as shown in the examples.</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "trips, zones = load_data('small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "ts = trip_statistics(trips)\n",
    "ts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python_session"
    }
   },
   "outputs": [],
   "source": [
    "main('large', 's3://cse6242-gburdell3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Athena PySpark",
   "language": "python",
   "name": "kepler_python_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
